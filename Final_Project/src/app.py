"""
Book Recommendation System - Streamlit App
H·ªá th·ªëng g·ª£i √Ω s√°ch s·ª≠ d·ª•ng SVD + Item-Item CF + Content-Based
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
from pathlib import Path
import sys
import matplotlib.pyplot as plt
import seaborn as sns

# Import utils
from utils import (
    get_book_info, get_books_by_author, get_books_by_publisher,
    get_similar_books_cf, get_svd_recommendations, get_top_rated_books,
    explain_recommendation, get_random_books, search_books,
    update_user_preference, rerank_recommendations_with_clicks,
    is_cold_start_user, get_fallback_recommendations
)

# Page config
st.set_page_config(
    page_title="Book Recommendation System",
    page_icon="üìö",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh
st.markdown("""
<style>
    .book-card {
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #ddd;
        margin: 0.5rem 0;
        background: white;
    }
    .book-title {
        font-weight: bold;
        font-size: 1.1rem;
        color: #1f77b4;
    }
    .book-meta {
        color: #666;
        font-size: 0.9rem;
    }
    .reason-tag {
        background: #e8f4f8;
        padding: 0.2rem 0.5rem;
        border-radius: 5px;
        font-size: 0.85rem;
        display: inline-block;
        margin-top: 0.5rem;
    }
    .section-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 1.5rem 0 1rem 0;
    }
</style>
""", unsafe_allow_html=True)


def get_data_path(relative_path: str) -> Path:
    """
    T√¨m ƒë∆∞·ªùng d·∫´n data/model file, h·ªó tr·ª£ c·∫£ local v√† deployment
    Th·ª≠ c√°c paths:
    1. Relative t·ª´ src/ (../dataset/...)
    2. Absolute t·ª´ project root (./dataset/...)
    3. T·ª´ current working directory
    """
    # Path t·ª´ src/ l√™n parent (local development)
    path1 = Path(__file__).parent.parent / relative_path
    
    # Path t·ª´ current working directory (deployment)
    path2 = Path(relative_path)
    
    # Path t·ª´ project root (n·∫øu ch·∫°y t·ª´ root)
    path3 = Path('.') / relative_path
    
    # Th·ª≠ t·ª´ng path
    for path in [path1, path2, path3]:
        if path.exists():
            return path
    
    # N·∫øu kh√¥ng t√¨m th·∫•y, tr·∫£ v·ªÅ path ƒë·∫ßu ti√™n (ƒë·ªÉ hi·ªÉn th·ªã l·ªói)
    return path1


@st.cache_resource
def load_data():
    """Load t·∫•t c·∫£ data v√† models"""
    try:
        # Load books
        books_path = get_data_path('dataset/cleaned/Books_cleaned.csv')
        books = pd.read_csv(books_path)

        # Load users
        users_path = get_data_path('dataset/cleaned/Users_cleaned.csv')
        users = pd.read_csv(users_path)

        # Load ratings
        ratings_path = get_data_path('dataset/cleaned/Ratings_cleaned.csv')
        ratings = pd.read_csv(ratings_path)

        # Load SVD model
        model_path = get_data_path('notebook/saved_models/svd_model.pkl')
        with open(model_path, 'rb') as f:
            svd_model = pickle.load(f)

        # Load item similarity matrix
        similarity_path = get_data_path('dataset/cleaned/item_similarity.pkl')
        with open(similarity_path, 'rb') as f:
            item_similarity = pickle.load(f)

        return books, users, ratings, svd_model, item_similarity

    except FileNotFoundError as e:
        st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {e}")
        st.info("üí° H√£y ch·∫°y `python compute_similarity.py` tr∆∞·ªõc ƒë·ªÉ t·∫°o item_similarity.pkl")
        st.info("üí° ƒê·∫£m b·∫£o c√°c file data v√† models ƒë√£ ƒë∆∞·ª£c copy v√†o ƒë√∫ng v·ªã tr√≠")
        st.stop()
    except Exception as e:
        st.error(f"‚ùå L·ªói khi load data: {e}")
        st.stop()


def display_book_card(isbn, books_df, reason="", score=None, show_button=True, key_suffix=""):
    """Hi·ªÉn th·ªã th√¥ng tin s√°ch d·∫°ng card"""
    book_info = get_book_info(isbn, books_df)

    if not book_info:
        return

    col1, col2 = st.columns([1, 3])

    with col1:
        # Hi·ªÉn th·ªã ·∫£nh
        try:
            st.image(book_info['image_m'], use_container_width=True)
        except:
            st.image("https://via.placeholder.com/150x200?text=No+Image", use_container_width=True)

    with col2:
        st.markdown(f"<div class='book-title'>{book_info['title']}</div>", unsafe_allow_html=True)
        st.markdown(f"<div class='book-meta'>‚úçÔ∏è {book_info['author']}</div>", unsafe_allow_html=True)
        st.markdown(f"<div class='book-meta'>üìÖ {book_info['year']} | üè¢ {book_info['publisher']}</div>",
                    unsafe_allow_html=True)

        if reason:
            explanation = explain_recommendation(isbn, book_info, reason, score)
            st.markdown(f"<div class='reason-tag'>{explanation}</div>", unsafe_allow_html=True)

        if show_button:
            # T·∫°o key duy nh·∫•t b·∫±ng c√°ch k·∫øt h·ª£p isbn, reason v√† key_suffix
            unique_key = f"btn_{reason}_{isbn}_{key_suffix}" if key_suffix else f"btn_{reason}_{isbn}"
            if st.button(f"üëÅÔ∏è Xem chi ti·∫øt", key=unique_key):
                st.session_state.selected_book = isbn
                st.rerun()


def show_book_detail(isbn, books_df, ratings_df, svd_model, similarity_df):
    """Hi·ªÉn th·ªã chi ti·∫øt s√°ch v√† c√°c g·ª£i √Ω li√™n quan"""
    book_info = get_book_info(isbn, books_df)

    if not book_info:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y th√¥ng tin s√°ch")
        return

    # L∆∞u v√†o history v·ªõi timestamp (ƒë·ªÉ t√≠nh recency weight)
    import time
    if 'clicked_books' not in st.session_state:
        st.session_state.clicked_books = []  # List of tuples: [(isbn, timestamp), ...]

    # Ki·ªÉm tra xem isbn ƒë√£ c√≥ ch∆∞a (ch·ªâ l·∫•y isbn, b·ªè qua timestamp)
    existing_isbns = [item[0] if isinstance(item, tuple) else item for item in st.session_state.clicked_books]
    
    if isbn not in existing_isbns:
        # Th√™m m·ªõi v·ªõi timestamp hi·ªán t·∫°i
        st.session_state.clicked_books.append((isbn, time.time()))
    else:
        # N·∫øu ƒë√£ c√≥, c·∫≠p nh·∫≠t timestamp (move to recent) - x√≥a c≈© v√† th√™m m·ªõi
        st.session_state.clicked_books = [
            item for item in st.session_state.clicked_books
            if (item[0] if isinstance(item, tuple) else item) != isbn
        ]
        st.session_state.clicked_books.append((isbn, time.time()))
        # Update user preference
        if 'user_profile' not in st.session_state:
            st.session_state.user_profile = {}
        st.session_state.user_profile = update_user_preference(isbn, books_df, st.session_state.user_profile)

    # N√∫t quay l·∫°i
    if st.button("‚¨ÖÔ∏è Quay l·∫°i"):
        st.session_state.selected_book = None
        st.rerun()

    st.markdown("---")

    # Th√¥ng tin chi ti·∫øt s√°ch
    col1, col2 = st.columns([1, 2])

    with col1:
        try:
            st.image(book_info['image_l'], use_container_width=True)
        except:
            st.image("https://via.placeholder.com/300x400?text=No+Image", use_container_width=True)

    with col2:
        st.markdown(f"# {book_info['title']}")
        st.markdown(f"### ‚úçÔ∏è {book_info['author']}")
        st.markdown(f"**üìÖ NƒÉm xu·∫•t b·∫£n:** {book_info['year']}")
        st.markdown(f"**üè¢ Nh√† xu·∫•t b·∫£n:** {book_info['publisher']}")
        st.markdown(f"**üìñ ISBN:** {book_info['isbn']}")

        # Th·ªëng k√™ ratings
        book_ratings = ratings_df[ratings_df['ISBN'] == isbn]
        if not book_ratings.empty:
            avg_rating = book_ratings['Book-Rating'].mean()
            num_ratings = len(book_ratings)
            st.markdown(f"**‚≠ê Rating:** {avg_rating:.1f}/10 ({num_ratings} ƒë√°nh gi√°)")

    st.markdown("---")

    # SECTION 1: Ng∆∞·ªùi ƒë·ªçc s√°ch n√†y c≈©ng th√≠ch (Item-Item CF)
    st.markdown("<div class='section-header'><h3>üë• Ng∆∞·ªùi ƒë·ªçc s√°ch n√†y c≈©ng th√≠ch</h3></div>", unsafe_allow_html=True)

    similar_cf = get_similar_books_cf(isbn, similarity_df, books_df, limit=5)

    if similar_cf:
        cols = st.columns(5)
        for idx, (sim_isbn, score) in enumerate(similar_cf):
            with cols[idx]:
                display_book_card(sim_isbn, books_df, reason='collaborative', score=score, show_button=True, key_suffix=f"cf_{idx}")
    else:
        st.info("Ch∆∞a c√≥ d·ªØ li·ªáu collaborative filtering cho s√°ch n√†y")

    # SECTION 2: S√°ch c√πng t√°c gi·∫£
    st.markdown("<div class='section-header'><h3>üìö S√°ch kh√°c c·ªßa t√°c gi·∫£</h3></div>", unsafe_allow_html=True)

    same_author = get_books_by_author(book_info['author'], books_df, exclude_isbn=isbn, limit=5)

    if same_author:
        cols = st.columns(5)
        for idx, auth_isbn in enumerate(same_author):
            with cols[idx]:
                display_book_card(auth_isbn, books_df, reason='same_author', show_button=True, key_suffix=f"auth_{idx}")
    else:
        st.info("Kh√¥ng t√¨m th·∫•y s√°ch kh√°c c·ªßa t√°c gi·∫£ n√†y")

    # SECTION 3: S√°ch c√πng NXB
    st.markdown("<div class='section-header'><h3>üè¢ S√°ch c√πng nh√† xu·∫•t b·∫£n</h3></div>", unsafe_allow_html=True)

    same_publisher = get_books_by_publisher(book_info['publisher'], books_df, exclude_isbn=isbn, limit=5)

    if same_publisher:
        cols = st.columns(5)
        for idx, pub_isbn in enumerate(same_publisher):
            with cols[idx]:
                display_book_card(pub_isbn, books_df, reason='same_publisher', show_button=True, key_suffix=f"pub_{idx}")
    else:
        st.info("Kh√¥ng t√¨m th·∫•y s√°ch kh√°c c·ªßa NXB n√†y")

    # SECTION 4: G·ª£i √Ω ri√™ng cho b·∫°n (SVD)
    if 'selected_user' in st.session_state and st.session_state.selected_user:
        st.markdown("<div class='section-header'><h3>‚≠ê G·ª£i √Ω ri√™ng cho b·∫°n</h3></div>", unsafe_allow_html=True)

        user_id = st.session_state.selected_user
        exclude_list = st.session_state.clicked_books if 'clicked_books' in st.session_state else [isbn]

        personalized = get_svd_recommendations(
            user_id, svd_model, books_df, ratings_df,
            limit=5, exclude_isbns=exclude_list
        )

        if personalized:
            cols = st.columns(5)
            for idx, (rec_isbn, pred_rating) in enumerate(personalized):
                with cols[idx]:
                    display_book_card(rec_isbn, books_df, reason='personalized', score=pred_rating, show_button=True, key_suffix=f"detail_{idx}")


def show_data_analysis(books_df, users_df, ratings_df):
    """Hi·ªÉn th·ªã ph√¢n t√≠ch v√† tr·ª±c quan h√≥a d·ªØ li·ªáu"""
    st.title("üìä Ph√¢n t√≠ch & Tr·ª±c quan h√≥a D·ªØ li·ªáu")
    
    # Set style cho plots
    sns.set_style("whitegrid")
    plt.rcParams['figure.figsize'] = (12, 6)
    plt.rcParams['font.size'] = 10
    
    # 1. Ph√¢n b·ªë Rating (Histogram)
    st.markdown("### üìà 1. Ph√¢n b·ªë Rating")
    fig1, ax1 = plt.subplots(figsize=(10, 6))
    ratings_df['Book-Rating'].hist(bins=20, ax=ax1, color='skyblue', edgecolor='black')
    ax1.set_xlabel('Rating', fontsize=12)
    ax1.set_ylabel('S·ªë l∆∞·ª£ng ƒë√°nh gi√°', fontsize=12)
    ax1.set_title('Ph√¢n b·ªë Rating c·ªßa ng∆∞·ªùi d√πng', fontsize=14, fontweight='bold')
    ax1.grid(True, alpha=0.3)
    st.pyplot(fig1)
    plt.close(fig1)
    
    # Th·ªëng k√™ rating
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Rating trung b√¨nh", f"{ratings_df['Book-Rating'].mean():.2f}")
    with col2:
        st.metric("Rating trung v·ªã", f"{ratings_df['Book-Rating'].median():.2f}")
    with col3:
        st.metric("Rating cao nh·∫•t", f"{ratings_df['Book-Rating'].max()}")
    with col4:
        st.metric("Rating th·∫•p nh·∫•t", f"{ratings_df['Book-Rating'].min()}")
    
    st.markdown("---")
    
    # 2. Top Items (Bar Chart)
    st.markdown("### üî• 2. Top 20 S√°ch ƒë∆∞·ª£c ƒë√°nh gi√° cao nh·∫•t")
    
    # T√≠nh to√°n top books
    book_ratings = ratings_df.groupby('ISBN').agg({
        'Book-Rating': ['mean', 'count']
    }).reset_index()
    book_ratings.columns = ['ISBN', 'avg_rating', 'num_ratings']
    book_ratings = book_ratings[book_ratings['num_ratings'] >= 20]  # √çt nh·∫•t 20 ƒë√°nh gi√°
    book_ratings = book_ratings.sort_values('avg_rating', ascending=False).head(20)
    
    # Merge v·ªõi books_df ƒë·ªÉ l·∫•y title
    top_books_merged = book_ratings.merge(books_df[['ISBN', 'Book-Title']], on='ISBN', how='left')
    top_books_merged['Book-Title'] = top_books_merged['Book-Title'].apply(
        lambda x: x[:50] + '...' if len(str(x)) > 50 else x
    )
    
    fig2, ax2 = plt.subplots(figsize=(12, 8))
    bars = ax2.barh(range(len(top_books_merged)), top_books_merged['avg_rating'], color='coral')
    ax2.set_yticks(range(len(top_books_merged)))
    ax2.set_yticklabels(top_books_merged['Book-Title'], fontsize=9)
    ax2.set_xlabel('Rating trung b√¨nh', fontsize=12)
    ax2.set_title('Top 20 S√°ch ƒë∆∞·ª£c ƒë√°nh gi√° cao nh·∫•t (‚â•20 ƒë√°nh gi√°)', fontsize=14, fontweight='bold')
    ax2.invert_yaxis()
    ax2.grid(True, alpha=0.3, axis='x')
    
    # Th√™m gi√° tr·ªã rating tr√™n m·ªói bar
    for i, (idx, row) in enumerate(top_books_merged.iterrows()):
        ax2.text(row['avg_rating'] + 0.1, i, f"{row['avg_rating']:.2f} ({int(row['num_ratings'])} ƒë√°nh gi√°)", 
                va='center', fontsize=8)
    
    plt.tight_layout()
    st.pyplot(fig2)
    plt.close(fig2)
    
    st.markdown("---")
    
    # 3. T·∫ßn su·∫•t nh√≥m s·∫£n ph·∫©m - Top Authors (Bar Chart)
    st.markdown("### ‚úçÔ∏è 3. Top 15 T√°c gi·∫£ c√≥ nhi·ªÅu s√°ch nh·∫•t")
    
    author_counts = books_df['Book-Author'].value_counts().head(15)
    
    fig3, ax3 = plt.subplots(figsize=(12, 6))
    bars = ax3.barh(range(len(author_counts)), author_counts.values, color='lightgreen')
    ax3.set_yticks(range(len(author_counts)))
    ax3.set_yticklabels(author_counts.index, fontsize=10)
    ax3.set_xlabel('S·ªë l∆∞·ª£ng s√°ch', fontsize=12)
    ax3.set_title('Top 15 T√°c gi·∫£ c√≥ nhi·ªÅu s√°ch nh·∫•t', fontsize=14, fontweight='bold')
    ax3.invert_yaxis()
    ax3.grid(True, alpha=0.3, axis='x')
    
    # Th√™m gi√° tr·ªã tr√™n m·ªói bar
    for i, (author, count) in enumerate(author_counts.items()):
        ax3.text(count + 5, i, str(count), va='center', fontsize=9)
    
    plt.tight_layout()
    st.pyplot(fig3)
    plt.close(fig3)
    
    st.markdown("---")
    
    # 4. T·∫ßn su·∫•t nh√≥m s·∫£n ph·∫©m - Top Publishers (Bar Chart)
    st.markdown("### üè¢ 4. Top 15 Nh√† xu·∫•t b·∫£n c√≥ nhi·ªÅu s√°ch nh·∫•t")
    
    publisher_counts = books_df['Publisher'].value_counts().head(15)
    
    fig4, ax4 = plt.subplots(figsize=(12, 6))
    bars = ax4.barh(range(len(publisher_counts)), publisher_counts.values, color='plum')
    ax4.set_yticks(range(len(publisher_counts)))
    ax4.set_yticklabels(publisher_counts.index, fontsize=10)
    ax4.set_xlabel('S·ªë l∆∞·ª£ng s√°ch', fontsize=12)
    ax4.set_title('Top 15 Nh√† xu·∫•t b·∫£n c√≥ nhi·ªÅu s√°ch nh·∫•t', fontsize=14, fontweight='bold')
    ax4.invert_yaxis()
    ax4.grid(True, alpha=0.3, axis='x')
    
    # Th√™m gi√° tr·ªã tr√™n m·ªói bar
    for i, (publisher, count) in enumerate(publisher_counts.items()):
        ax4.text(count + 5, i, str(count), va='center', fontsize=9)
    
    plt.tight_layout()
    st.pyplot(fig4)
    plt.close(fig4)
    
    st.markdown("---")
    
    # 5. Heatmap - Rating theo nƒÉm xu·∫•t b·∫£n v√† s·ªë l∆∞·ª£ng ƒë√°nh gi√°
    st.markdown("### üî• 5. Heatmap: Rating trung b√¨nh theo NƒÉm xu·∫•t b·∫£n")
    
    # Merge ratings v·ªõi books ƒë·ªÉ l·∫•y nƒÉm xu·∫•t b·∫£n
    ratings_with_year = ratings_df.merge(
        books_df[['ISBN', 'Year-Of-Publication']], 
        on='ISBN', 
        how='left'
    )
    
    # L·ªçc nƒÉm h·ª£p l·ªá (1900-2024)
    ratings_with_year = ratings_with_year[
        (ratings_with_year['Year-Of-Publication'] >= 1900) & 
        (ratings_with_year['Year-Of-Publication'] <= 2024)
    ]
    
    # T√≠nh rating trung b√¨nh theo nƒÉm
    year_rating = ratings_with_year.groupby('Year-Of-Publication')['Book-Rating'].mean().reset_index()
    year_rating.columns = ['Year', 'Avg_Rating']
    
    # T·∫°o pivot table cho heatmap (nh√≥m theo th·∫≠p k·ª∑)
    ratings_with_year['Decade'] = (ratings_with_year['Year-Of-Publication'] // 10) * 10
    decade_rating = ratings_with_year.groupby('Decade')['Book-Rating'].mean().reset_index()
    
    # T·∫°o heatmap data
    heatmap_data = decade_rating.set_index('Decade')['Book-Rating'].to_frame().T
    
    fig5, ax5 = plt.subplots(figsize=(14, 4))
    sns.heatmap(heatmap_data, annot=True, fmt='.2f', cmap='YlOrRd', 
                cbar_kws={'label': 'Rating trung b√¨nh'}, ax=ax5, linewidths=0.5)
    ax5.set_title('Rating trung b√¨nh theo Th·∫≠p k·ª∑ xu·∫•t b·∫£n', fontsize=14, fontweight='bold')
    ax5.set_xlabel('Th·∫≠p k·ª∑', fontsize=12)
    ax5.set_ylabel('')
    ax5.set_yticklabels(['Rating TB'], rotation=0)
    plt.tight_layout()
    st.pyplot(fig5)
    plt.close(fig5)
    
    # Hi·ªÉn th·ªã b·∫£ng chi ti·∫øt
    with st.expander("üìã Xem chi ti·∫øt Rating theo nƒÉm"):
        st.dataframe(year_rating.sort_values('Year', ascending=False), use_container_width=True)
    
    st.markdown("---")
    
    # 6. Th·ªëng k√™ t·ªïng quan
    st.markdown("### üìä 6. Th·ªëng k√™ T·ªïng quan")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### üìö S√°ch")
        st.metric("T·ªïng s·ªë s√°ch", f"{len(books_df):,}")
        st.metric("S·ªë t√°c gi·∫£", f"{books_df['Book-Author'].nunique():,}")
        st.metric("S·ªë nh√† xu·∫•t b·∫£n", f"{books_df['Publisher'].nunique():,}")
    
    with col2:
        st.markdown("#### üë• Ng∆∞·ªùi d√πng")
        st.metric("T·ªïng s·ªë users", f"{len(users_df):,}")
        st.metric("S·ªë location", f"{users_df['Location'].nunique():,}")
        avg_age = users_df['Age'].mean()
        st.metric("Tu·ªïi trung b√¨nh", f"{avg_age:.1f}")
    
    with col3:
        st.markdown("#### ‚≠ê ƒê√°nh gi√°")
        st.metric("T·ªïng s·ªë ratings", f"{len(ratings_df):,}")
        st.metric("S√°ch ƒë∆∞·ª£c ƒë√°nh gi√°", f"{ratings_df['ISBN'].nunique():,}")
        st.metric("Users ƒë√£ ƒë√°nh gi√°", f"{ratings_df['User-ID'].nunique():,}")


def main():
    """Main app"""

    # Load data
    with st.spinner("üîÑ ƒêang load d·ªØ li·ªáu..."):
        books_df, users_df, ratings_df, svd_model, similarity_df = load_data()

    # Initialize session state
    if 'selected_book' not in st.session_state:
        st.session_state.selected_book = None
    if 'clicked_books' not in st.session_state:
        st.session_state.clicked_books = []
    if 'user_profile' not in st.session_state:
        st.session_state.user_profile = {}
    if 'last_user_id' not in st.session_state:
        st.session_state.last_user_id = None
    if 'current_page' not in st.session_state:
        st.session_state.current_page = "G·ª£i √Ω s√°ch"
    
    # Sidebar (chung cho c·∫£ 2 tabs)
    with st.sidebar:
        st.title("üìö Book Recommender")

        # User selection - C·∫£i thi·ªán v·ªõi text input
        st.subheader("üë§ Ch·ªçn User ID")
        
        # Cache user IDs list
        if 'user_ids_list' not in st.session_state:
            st.session_state.user_ids_list = sorted(users_df['User-ID'].unique())
        
        # Text input v·ªõi placeholder
        user_input = st.text_input(
            "Nh·∫≠p User ID (ho·∫∑c ƒë·ªÉ tr·ªëng)",
            value="",
            placeholder="VD: 276847",
            key="user_id_input"
        )
        
        # Validate v√† convert user ID
        selected_user = None
        if user_input.strip():
            try:
                user_id = int(user_input.strip())
                if user_id in st.session_state.user_ids_list:
                    selected_user = user_id
                else:
                    st.warning(f"‚ö†Ô∏è User ID {user_id} kh√¥ng t·ªìn t·∫°i trong h·ªá th·ªëng")
                    # G·ª£i √Ω user ID g·∫ßn nh·∫•t
                    user_ids_array = np.array(st.session_state.user_ids_list)
                    closest_idx = np.abs(user_ids_array - user_id).argmin()
                    closest_user = user_ids_array[closest_idx]
                    st.info(f"üí° G·ª£i √Ω: User ID {closest_user} (g·∫ßn nh·∫•t)")
            except ValueError:
                st.error("‚ùå Vui l√≤ng nh·∫≠p s·ªë User ID h·ª£p l·ªá")
        
        # Reset clicked_books v√† user_profile khi user thay ƒë·ªïi
        # CH·ªà reset khi: ƒë·ªïi t·ª´ user n√†y sang user kh√°c (KH√îNG reset khi None ‚Üí user ID)
        # M·ª•c ƒë√≠ch: Gi·ªØ clicked books t·ª´ anonymous ƒë·ªÉ x·ª≠ l√Ω cold start
        if st.session_state.last_user_id is not None and st.session_state.last_user_id != selected_user:
            st.session_state.clicked_books = []
            st.session_state.user_profile = {}
            st.session_state.selected_book = None  # Reset selected book khi ƒë·ªïi user
            # X√≥a cache random books ƒë·ªÉ refresh
            if 'random_books_list' in st.session_state:
                del st.session_state.random_books_list
        st.session_state.selected_user = selected_user
        st.session_state.last_user_id = selected_user

        # Hi·ªÉn th·ªã User ID hi·ªán t·∫°i (n·∫øu c√≥)
        if selected_user:
            user_info = users_df[users_df['User-ID'] == selected_user].iloc[0]
            st.success(f"‚úÖ User ID: **{selected_user}**")
            st.info(f"üìç {user_info['Location']}\n\nüéÇ Tu·ªïi: {user_info['Age']}")
            
            # N√∫t x√≥a User
            if st.button("üóëÔ∏è X√≥a User", use_container_width=True):
                st.session_state.selected_user = None
                st.rerun()
        else:
            st.info("üí° Nh·∫≠p User ID ƒë·ªÉ xem g·ª£i √Ω c√° nh√¢n h√≥a")

        st.markdown("---")

        # Search - C·∫£i thi·ªán v·ªõi container scrollable
        st.subheader("üîç T√¨m ki·∫øm s√°ch")
        search_query = st.text_input(
            "Nh·∫≠p t√™n s√°ch ho·∫∑c t√°c gi·∫£",
            placeholder="VD: Harry Potter, J.K. Rowling...",
            key="search_input"
        )

        if search_query and len(search_query.strip()) >= 2:
            with st.spinner("üîç ƒêang t√¨m ki·∫øm..."):
                search_results = search_books(search_query, books_df, limit=20)
            
            if not search_results.empty:
                st.success(f"‚úÖ T√¨m th·∫•y {len(search_results)} k·∫øt qu·∫£")

                # Container scrollable cho k·∫øt qu·∫£
                with st.container():
                    for idx, (_, book) in enumerate(search_results.iterrows()):
                        # Hi·ªÉn th·ªã compact h∆°n
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            title = book['Book-Title'][:60] + "..." if len(book['Book-Title']) > 60 else book['Book-Title']
                            author = book['Book-Author'][:30] + "..." if len(book['Book-Author']) > 30 else book['Book-Author']
                            st.markdown(f"**{title}**")
                            st.caption(f"‚úçÔ∏è {author}")
                        
                        with col2:
                            if st.button("üëâ", key=f"search_btn_{book['ISBN']}", help="Xem chi ti·∫øt"):
                                st.session_state.selected_book = book['ISBN']
                                st.rerun()
                        
                        if idx < len(search_results) - 1:
                            st.divider()
            else:
                st.info("üîç Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£. Th·ª≠ t·ª´ kh√≥a kh√°c!")
        elif search_query and len(search_query.strip()) < 2:
            st.info("üí° Nh·∫≠p √≠t nh·∫•t 2 k√Ω t·ª± ƒë·ªÉ t√¨m ki·∫øm")

        st.markdown("---")

        # History
        if st.session_state.clicked_books:
            st.subheader("üìú L·ªãch s·ª≠ xem")
            st.write(f"ƒê√£ xem {len(st.session_state.clicked_books)} s√°ch")

            if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠"):
                st.session_state.clicked_books = []
                st.session_state.user_profile = {}
                st.rerun()

        # Stats
        st.markdown("---")
        st.subheader("üìä Th·ªëng k√™")
        st.metric("T·ªïng s·ªë s√°ch", f"{len(books_df):,}")
        st.metric("T·ªïng s·ªë users", f"{len(users_df):,}")
        st.metric("T·ªïng s·ªë ratings", f"{len(ratings_df):,}")
    
    # Navigation tabs
    tab1, tab2 = st.tabs(["üìö G·ª£i √Ω s√°ch", "üìä Ph√¢n t√≠ch d·ªØ li·ªáu"])
    
    with tab1:
        # Main content
        st.title("üìö H·ªá Th·ªëng G·ª£i √ù S√°ch")

        # Hi·ªÉn th·ªã book detail n·∫øu ƒë√£ ch·ªçn
        if st.session_state.selected_book:
            show_book_detail(
                st.session_state.selected_book,
                books_df, ratings_df, svd_model, similarity_df
            )
        else:
            # Trang ch·ªß
            st.markdown("### Ch√†o m·ª´ng ƒë·∫øn v·ªõi h·ªá th·ªëng g·ª£i √Ω s√°ch!")
            st.markdown("Ch·ªçn user ID ·ªü sidebar v√† kh√°m ph√° c√°c g·ª£i √Ω s√°ch ph√π h·ª£p v·ªõi b·∫°n.")

        # Top rated books
        st.markdown("<div class='section-header'><h3>üî• S√°ch ƒë∆∞·ª£c ƒë√°nh gi√° cao nh·∫•t</h3></div>", unsafe_allow_html=True)

        top_books = get_top_rated_books(ratings_df, books_df, min_ratings=20, limit=10)

        cols = st.columns(5)
        for idx, (isbn, avg_rating, num_ratings) in enumerate(top_books[:5]):
            with cols[idx]:
                display_book_card(isbn, books_df, reason='top_rated', score=avg_rating, show_button=True, key_suffix=f"top_{idx}")

        cols = st.columns(5)
        for idx, (isbn, avg_rating, num_ratings) in enumerate(top_books[5:10]):
            with cols[idx]:
                display_book_card(isbn, books_df, reason='top_rated', score=avg_rating, show_button=True, key_suffix=f"top_{idx+5}")

        # Random books ƒë·ªÉ explore
        st.markdown("<div class='section-header'><h3>üé≤ Kh√°m ph√° ng·∫´u nhi√™n</h3></div>", unsafe_allow_html=True)

        # Cache random books trong session_state ƒë·ªÉ tr√°nh thay ƒë·ªïi khi rerun
        if 'random_books_list' not in st.session_state:
            st.session_state.random_books_list = get_random_books(books_df, n=10)
        random_isbns = st.session_state.random_books_list

        cols = st.columns(5)
        for idx, isbn in enumerate(random_isbns[:5]):
            with cols[idx]:
                display_book_card(isbn, books_df, reason='random', show_button=True, key_suffix=f"rand_{idx}")

        cols = st.columns(5)
        for idx, isbn in enumerate(random_isbns[5:10]):
            with cols[idx]:
                display_book_card(isbn, books_df, reason='random', show_button=True, key_suffix=f"rand_{idx+5}")

        # Personalized n·∫øu ƒë√£ ch·ªçn user
        if st.session_state.selected_user:
            st.markdown("<div class='section-header'><h3>‚≠ê G·ª£i √Ω d√†nh ri√™ng cho b·∫°n</h3></div>",
                        unsafe_allow_html=True)

            user_id = st.session_state.selected_user
            
            # Ki·ªÉm tra cold start user
            is_new_user = is_cold_start_user(user_id, ratings_df)
            
            # L·∫•y clicked_books (c√≥ th·ªÉ t·ª´ anonymous ho·∫∑c sau khi login)
            clicked_books_data = st.session_state.clicked_books.copy() if st.session_state.clicked_books else []
            # Extract ISBNs ƒë·ªÉ exclude (c√≥ th·ªÉ l√† list of tuples ho·∫∑c list of strings)
            exclude_list = [
                item[0] if isinstance(item, tuple) else item 
                for item in clicked_books_data
            ]

            # Try SVD first
            personalized = get_svd_recommendations(
                user_id, svd_model, books_df, ratings_df,
                limit=15,  # L·∫•y nhi·ªÅu h∆°n ƒë·ªÉ rerank
                exclude_isbns=exclude_list if exclude_list else None
            )

            # X·ª≠ l√Ω cold start: N·∫øu SVD fail ho·∫∑c tr·∫£ v·ªÅ √≠t (user m·ªõi)
            use_fallback = False
            if not personalized or (is_new_user and len(personalized) < 5):
                use_fallback = True
                personalized = get_fallback_recommendations(
                    clicked_books_data,
                    similarity_df,
                    books_df,
                    ratings_df,
                    limit=15,
                    exclude_isbns=exclude_list if exclude_list else None
                )
                
                # User feedback cho cold start
                if is_new_user:
                    if clicked_books_data:
                        st.info("üí° B·∫°n l√† user m·ªõi! Ch√∫ng t√¥i ƒëang g·ª£i √Ω d·ª±a tr√™n s√°ch b·∫°n ƒë√£ xem khi ch∆∞a ƒëƒÉng nh·∫≠p.")
                    else:
                        st.info("üí° B·∫°n l√† user m·ªõi! H√£y kh√°m ph√° s√°ch ph·ªï bi·∫øn ho·∫∑c click v√†o s√°ch ƒë·ªÉ nh·∫≠n g·ª£i √Ω c√° nh√¢n h√≥a.")
                elif not personalized:
                    st.warning("‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫°o g·ª£i √Ω t·ª´ SVD. ƒêang s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p thay th·∫ø.")

            # Rerank d·ª±a tr√™n clicked books (n·∫øu c√≥ v√† kh√¥ng ph·∫£i fallback ho·∫∑c fallback nh∆∞ng c√≥ clicked books)
            debug_info = None
            if personalized and exclude_list and (not use_fallback or clicked_books_data):
                personalized, debug_info = rerank_recommendations_with_clicks(
                    personalized,
                    clicked_books_data,  # Truy·ªÅn list of tuples (isbn, timestamp) ƒë·ªÉ t√≠nh recency
                    similarity_df,
                    books_df=books_df,  # C·∫ßn cho TF-IDF
                    boost_factor=0.25,  # Boost 25% cho CF similarity
                    use_tfidf=True,     # B·∫≠t TF-IDF
                    tfidf_boost_factor=0.15,  # Boost 15% cho TF-IDF similarity
                    return_debug_info=True,  # Tr·∫£ v·ªÅ debug info
                    use_weighted_sum=True,  # B·∫≠t weighted sum (xem x√©t t·∫•t c·∫£ clicked books)
                    use_recency_weight=True,  # B·∫≠t recency weighting (∆∞u ti√™n s√°ch g·∫ßn ƒë√¢y)
                    recency_decay_rate=0.1  # Exponential decay rate (0.1 = decay ch·∫≠m)
                )
                # Ch·ªâ hi·ªÉn th·ªã caption n·∫øu kh√¥ng ph·∫£i fallback (v√¨ fallback ƒë√£ c√≥ message ri√™ng)
                if not use_fallback:
                    st.caption("üîÑ G·ª£i √Ω ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t d·ª±a tr√™n s√°ch b·∫°n ƒë√£ xem (CF + Content-Based)")
                
                # Debug panel - Hi·ªÉn th·ªã chi ti·∫øt rerank
                with st.expander("üîç Xem chi ti·∫øt rerank (Debug)", expanded=False):
                    st.markdown("### üìö S√°ch b·∫°n ƒë√£ xem:")
                    for clicked_isbn in exclude_list:
                        clicked_book = books_df[books_df['ISBN'] == clicked_isbn]
                        if not clicked_book.empty:
                            st.write(f"- **{clicked_book.iloc[0]['Book-Title']}** (ISBN: {clicked_isbn})")
                    
                    st.markdown("---")
                    st.markdown("### üìä Top 10 s√°ch ƒë∆∞·ª£c rerank:")
                    
                    # Hi·ªÉn th·ªã top 10 v·ªõi debug info
                    for rank, (isbn, final_score) in enumerate(personalized[:10], 1):
                        if isbn in debug_info:
                            info = debug_info[isbn]
                            book = books_df[books_df['ISBN'] == isbn]
                            book_title = book.iloc[0]['Book-Title'] if not book.empty else isbn
                            
                            col1, col2 = st.columns([3, 1])
                            with col1:
                                st.markdown(f"**{rank}. {book_title}**")
                                st.caption(f"ISBN: {isbn}")
                            
                            with col2:
                                st.metric("Final Score", f"{final_score:.3f}")
                            
                            # Chi ti·∫øt boost
                            details = []
                            if info['cf_similarity'] > 0:
                                cf_detail = f"CF: {info['cf_similarity']:.3f} (+{info['cf_boost']:.3f})"
                                if info.get('use_weighted_sum') and info.get('cf_similarities_count', 0) > 1:
                                    cf_detail += f" [weighted sum t·ª´ {info['cf_similarities_count']} s√°ch]"
                                elif info.get('best_cf_clicked'):
                                    cf_detail += f" [max t·ª´ {info['best_cf_clicked'][:12]}...]"
                                details.append(cf_detail)
                                
                                # Hi·ªÉn th·ªã chi ti·∫øt t·ª´ng clicked book (n·∫øu c√≥ nhi·ªÅu h∆°n 1)
                                if info.get('all_cf_similarities') and len(info['all_cf_similarities']) > 1:
                                    cf_details_list = []
                                    for clicked_isbn, sim_info in info['all_cf_similarities'].items():
                                        recency_str = f", recency: {sim_info['recency_weight']:.2f}" if info.get('use_recency_weight') and sim_info['recency_weight'] < 1.0 else ""
                                        cf_details_list.append(f"{clicked_isbn[:8]}...: {sim_info['raw_similarity']:.2f}{recency_str}")
                                    st.caption(f"   üìä CF v·ªõi t·ª´ng clicked: {', '.join(cf_details_list)}")
                                    
                            if info['tfidf_similarity'] > 0:
                                tfidf_detail = f"TF-IDF: {info['tfidf_similarity']:.3f} (+{info['tfidf_boost']:.3f})"
                                if info.get('use_weighted_sum') and info.get('tfidf_similarities_count', 0) > 1:
                                    tfidf_detail += f" [weighted sum t·ª´ {info['tfidf_similarities_count']} s√°ch]"
                                elif info.get('best_tfidf_clicked'):
                                    tfidf_detail += f" [max t·ª´ {info['best_tfidf_clicked'][:12]}...]"
                                details.append(tfidf_detail)
                                
                                # Hi·ªÉn th·ªã chi ti·∫øt TF-IDF
                                if info.get('all_tfidf_similarities') and len(info['all_tfidf_similarities']) > 1:
                                    tfidf_details_list = []
                                    for clicked_isbn, sim_info in info['all_tfidf_similarities'].items():
                                        recency_str = f", recency: {sim_info['recency_weight']:.2f}" if info.get('use_recency_weight') and sim_info['recency_weight'] < 1.0 else ""
                                        tfidf_details_list.append(f"{clicked_isbn[:8]}...: {sim_info['raw_similarity']:.2f}{recency_str}")
                                    st.caption(f"   üìä TF-IDF v·ªõi t·ª´ng clicked: {', '.join(tfidf_details_list)}")
                            
                            if details:
                                st.caption(" | ".join(details))
                            else:
                                st.caption("Kh√¥ng c√≥ boost (gi·ªØ nguy√™n score)")
                            
                            st.caption(f"Base score: {info['base_score']:.3f} ‚Üí Final: {info['final_score']:.3f}")
                            st.markdown("---")

            # Gi·ªõi h·∫°n 10 items
            personalized = personalized[:10] if personalized else []

            if personalized:
                cols = st.columns(5)
                for idx, (isbn, pred_rating) in enumerate(personalized[:5]):
                    with cols[idx]:
                        display_book_card(isbn, books_df, reason='personalized', score=pred_rating,
                                          show_button=True, key_suffix=f"pers_{idx}")

                cols = st.columns(5)
                for idx, (isbn, pred_rating) in enumerate(personalized[5:10]):
                    with cols[idx]:
                        display_book_card(isbn, books_df, reason='personalized', score=pred_rating,
                                          show_button=True, key_suffix=f"pers_{idx + 5}")
    
    with tab2:
        show_data_analysis(books_df, users_df, ratings_df)


if __name__ == "__main__":
    main()